BENCHMARK="gsm8k" # "gsm8k", "math"
OUPTUT_DIR="outputs/Qwen2.5-7B-Instruct/${BENCHMARK}/" # Llama-3.1-8B-Instruct, Qwen2.5-7B-Instruct
MODEL_PATH="/your_model_path/Qwen2.5-7B-Instruct" # /home/xiaheming/data/pretrained_models/Qwen/Qwen2.5-7B-Instruct
MODEL_SIZE="7b"
MODEL_TYPE="qwen" # "llama3", "qwen"
TEST_CONF="configs/${BENCHMARK}_config.json"

# Generation Settings
MAX_NUM_EXAMPLES=100000000000000 # 100000000000000
MAX_NEW_TOKENS=512 # 512 for gsm8k, 1024 for math
EVAL_BATCH_SIZE=16
TEMPERATURE=0.0
SEED=42

# TokenSKip Settings
ADAPTER_PATH="/your_model_path/TokenSkip-Qwen2.5-7B-Instruct-GSM8K"
COMPRESSION_RATIO=0.5

CUDA_VISIBLE_DEVICES=0 python ./evaluation.py --output-dir ${OUPTUT_DIR} --model-path ${MODEL_PATH} --tokenizer-path ${MODEL_PATH} \
    --model-size ${MODEL_SIZE} --model-type ${MODEL_TYPE} --test-conf ${TEST_CONF}  --max_num_examples ${MAX_NUM_EXAMPLES} \
    --max_new_tokens ${MAX_NEW_TOKENS} --eval_batch_size ${EVAL_BATCH_SIZE} --temperature ${TEMPERATURE} --seed ${SEED} --benchmark ${BENCHMARK} \
    --adapter-path ${ADAPTER_PATH} --compression_ratio ${COMPRESSION_RATIO} --use_adapter
